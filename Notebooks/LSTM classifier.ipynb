{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08b73ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 09:44:43.557523: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "import mysql.connector\n",
    "import glob\n",
    "import traceback\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd854a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample run for time aware models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a64b15d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_maker_pom_test (i):\n",
    "    df = pd.read_csv(i, index_col = [0])\n",
    "    df = df.iloc[df[df.timestamp.str.contains(df.timestamp.apply(lambda x: x.split(' ')[0]).unique()[-360])].iloc[0].name:]\n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "    times = pd.DataFrame(df['timestamp'])\n",
    "    pl = pd.DataFrame(df['pl'])\n",
    "    dff = pd.DataFrame()\n",
    "    st = datetime.strptime(df.timestamp.iloc[ 0 ], '%Y-%m-%d %H:%M:%S') #+ timedelta(days = 1)\n",
    "    et = datetime.strptime(df.timestamp.iloc[-1 ], '%Y-%m-%d %H:%M:%S')\n",
    "    while True:\n",
    "        if st > et + timedelta(days = 1):\n",
    "            break\n",
    "        srt = datetime.strftime(st , '%Y-%m-%d %H:%M:%S')\n",
    "        tmp = df[df['timestamp'].str.contains(srt.split(' ')[0])].copy()\n",
    "        tmp.drop(columns = ['timestamp'], inplace = True)\n",
    "        lis = list(tmp.columns)\n",
    "        if len(tmp) == 0:\n",
    "            st += timedelta(days = 1)\n",
    "            continue\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(tmp)\n",
    "        tmp = scaler.transform(tmp)\n",
    "        \n",
    "        tmp = pd.DataFrame(tmp, columns = lis)\n",
    "        dff = pd.concat([\n",
    "            dff,\n",
    "            tmp\n",
    "        ])\n",
    "        del scaler\n",
    "        st += timedelta(days = 1)\n",
    "    dff.reset_index(drop = True, inplace = True)\n",
    "    dff['pl'] = pl['pl']\n",
    "    return dff,times,df\n",
    "\n",
    "def prepare_data_com_pom(df,i,times,timesteps):\n",
    "    pl = df[['pl']]\n",
    "    df['class'] = [1 if j[0] >0 else 0 for j in pl.values]\n",
    "    y = df[['class']]\n",
    "    df['pl'] = pl\n",
    "    df['class'] = y\n",
    "    col = list(df.columns)\n",
    "    tdf = pd.DataFrame(columns = ['timestamp'])\n",
    "    \n",
    "    dt = times.iloc[0].values[0]\n",
    "    dt = dt.split(' ')[0]\n",
    "    et = times.iloc[-1].values[0]\n",
    "    et = et.split(' ')[0]\n",
    "    dtt = datetime.strptime(dt, '%Y-%m-%d')\n",
    "    ett = datetime.strptime(et, '%Y-%m-%d')\n",
    "    fd = pd.DataFrame(columns = col)\n",
    "    fdd = df.copy()\n",
    "    while dtt < ett + timedelta(days = 1):\n",
    "        \n",
    "        try:\n",
    "            ind = times[times['timestamp'].str.contains(dtt.strftime('%Y-%m-%d'))].iloc[-1].name\n",
    "            tdf = pd.concat([\n",
    "                tdf,\n",
    "                pd.DataFrame(\n",
    "                    times[\n",
    "                        times['timestamp'].str.contains(\n",
    "                            dtt.strftime('%Y-%m-%d')\n",
    "                        )].iloc[-1]\n",
    "                ).T\n",
    "            ])\n",
    "        except:\n",
    "            dtt+= timedelta(days = 1)\n",
    "            continue \n",
    "        ad = pd.DataFrame(fdd.loc[ind-timesteps:ind],columns = col)\n",
    "        ad = ad[col]\n",
    "        fd = pd.concat([\n",
    "            fd,\n",
    "            ad\n",
    "        ])\n",
    "        dtt += timedelta(days = 1)\n",
    "    fd.reset_index(drop = True, inplace = True)\n",
    "    col = fd.columns\n",
    "    return fd, col,tdf\n",
    "\n",
    "def plc_pom(fd):\n",
    "    data = fd['pl']\n",
    "    range_50 = np.percentile(data, [16, 84]) \n",
    "    range_75 = np.percentile(data, [3, 97])  \n",
    "    range_100 = np.percentile(data, [0, 100])\n",
    "    fd['plc'] = fd['pl'].apply(\n",
    "        lambda x : 1 if (x <= range_50[1] and x > 0 ) else( \n",
    "            -1\n",
    "            if (x > range_50[0] and x < 0) else(\n",
    "                2\n",
    "                if (x > range_50[1] and x < range_75[1]) else(\n",
    "                    -2\n",
    "                    if (x < range_50[0] and x > range_75[0]) else (\n",
    "                        3 if (x > range_75[1]) else(\n",
    "                            -3 if (x < range_75[0]) else 0\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return fd, (range_50,range_75,range_100)\n",
    "\n",
    "def plc_pom_4(fd):\n",
    "    data = fd['pl']\n",
    "    range_45 = np.percentile(data, [27.5, 72.5])\n",
    "    range_50 = np.percentile(data, [16, 84]) \n",
    "    range_75 = np.percentile(data, [3, 97])  \n",
    "    range_100 = np.percentile(data, [0, 100])\n",
    "    fd['plc'] = fd['pl'].apply(\n",
    "        lambda x : 1 if (x > 0 and x <= range_45[1]) else(\n",
    "            -1 if(x<0 and x > range_45[0] ) else(\n",
    "            2 if(x >= range_45[1] and x < range_50[1]) else(\n",
    "            -2 if (x <= range_45[0] and x > range_50[0]) else(\n",
    "            3 if (x >= range_50[1] and x < range_75[1]) else(\n",
    "            -3 if (x <= range_50[0] and x > range_75[0]) else(\n",
    "            4 if (x >= range_75[1]) else (\n",
    "            -4 if (x <= range_75[0]) else 0\n",
    "            )\n",
    "            )\n",
    "            )\n",
    "            )\n",
    "            )\n",
    "        )\n",
    "    ))\n",
    "    return fd, (range_50,range_75,range_100)\n",
    "\n",
    "def splitter_com(df,timesteps):\n",
    "    xx = np.empty((0,timesteps + 1,len(df.columns) - 3))\n",
    "    yy = np.empty((0,timesteps + 1 ,1))\n",
    "    pll = np.empty((0,timesteps + 1 , 1))\n",
    "    plcc = np.empty((0,timesteps + 1 , 1))\n",
    "    \n",
    "    yt = df[['class']]\n",
    "    pltt = df[['pl']]\n",
    "    pltc = df[['plc']]\n",
    "    \n",
    "    loop = len(df) / (timesteps+1)\n",
    "    for i in range(0,int(loop)):\n",
    "        x = df.loc[i*(timesteps+1): ((i+1) *(timesteps + 1 )) - 1].copy()\n",
    "        y = yt.loc[i*(timesteps+1): ((i+1) *(timesteps + 1 )) - 1]\n",
    "        pl = pltt.loc[i*(timesteps+1): ((i+1) *(timesteps + 1 )) - 1]\n",
    "        plc = pltc.loc[i*(timesteps+1): ((i+1) *(timesteps + 1 )) - 1]\n",
    "        \n",
    "        x.drop(columns = ['class','pl','plc'], inplace = True)\n",
    "        x = np.array(x).reshape(1,timesteps+1,len(x.columns))\n",
    "        y = np.array(y).reshape(1,timesteps+1,1)\n",
    "        pl = np.array(pl).reshape(1,timesteps+1,1)\n",
    "        plc = np.array(plc).reshape(1,timesteps+1,1)\n",
    "        \n",
    "        xx = np.append(xx,x,axis = 0)\n",
    "        yy = np.append(yy,y, axis = 0)\n",
    "        pll = np.append(pll,pl, axis = 0)\n",
    "        plcc = np.append(plcc,plc, axis = 0)\n",
    "    return xx,yy,pll,plcc\n",
    "\n",
    "def padder_com(x,y,pl,plc,sli,timesteps):\n",
    "    xtt = np.empty((0,timesteps+1,x.shape[2]))\n",
    "    ytt = np.empty((0,timesteps+1,y.shape[2]))\n",
    "    plttt = np.empty((0,timesteps+1,pl.shape[2]))\n",
    "    pltcc = np.empty((0,timesteps+1,plc.shape[2]))\n",
    "    xee = np.empty((0,timesteps+1,x.shape[2]))\n",
    "    yee = np.empty((0,timesteps+1,y.shape[2]))\n",
    "    plee = np.empty((0,timesteps+1,pl.shape[2]))\n",
    "    plecc = np.empty((0,timesteps+1,plc.shape[2]))\n",
    "    for i in range(0,len(x) - sli):\n",
    "        for j in range(1,timesteps+2):\n",
    "            xt = np.pad(\n",
    "                x[i][- j: ].reshape(1,j,x.shape[2]),\n",
    "                ((0, 0), (timesteps + 1 -j, 0), (0, 0)),\n",
    "                mode = 'constant',\n",
    "                constant_values=-1\n",
    "            )\n",
    "            yt = np.pad(\n",
    "                y[i][- j: ].reshape(1,j,y.shape[2]),\n",
    "                ((0, 0), (timesteps + 1-j, 0), (0, 0)),\n",
    "                mode = 'constant', \n",
    "                constant_values=-1\n",
    "            )\n",
    "            pltt = np.pad(\n",
    "                pl[i][- j: ].reshape(1,j,pl.shape[2]),\n",
    "                ((0, 0), (timesteps + 1 - j , 0), (0, 0)),\n",
    "                mode = 'constant', \n",
    "                constant_values=0\n",
    "            )\n",
    "            pltc = np.pad(\n",
    "                plc[i][- j: ].reshape(1,j,plc.shape[2]),\n",
    "                ((0, 0), (timesteps + 1 - j , 0), (0, 0)),\n",
    "                mode = 'constant', \n",
    "                constant_values=0\n",
    "            )\n",
    "            xtt = np.append(xtt,xt, axis = 0)\n",
    "            ytt = np.append(ytt,yt, axis = 0)\n",
    "            plttt = np.append(plttt,pltt, axis = 0)\n",
    "            pltcc = np.append(pltcc,pltc, axis = 0)\n",
    "    for i in range(len(x) - sli, len(x)):\n",
    "        for j in range(1,timesteps+2):\n",
    "            xt = np.pad(\n",
    "                x[i][- j: ].reshape(1,j,x.shape[2]),\n",
    "                ((0, 0), (timesteps + 1 - j, 0), (0, 0)),\n",
    "                mode = 'constant', \n",
    "                constant_values=-1\n",
    "            )\n",
    "            yt = np.pad(\n",
    "                y[i][- j: ].reshape(1,j,y.shape[2]),\n",
    "                ((0, 0), (timesteps + 1 - j, 0), (0, 0)),\n",
    "                mode = 'constant', \n",
    "                constant_values=-1\n",
    "            )\n",
    "            pltt = np.pad(\n",
    "                pl[i][- j: ].reshape(1,j,pl.shape[2]),\n",
    "                ((0, 0), (timesteps + 1 - j, 0), (0, 0)),\n",
    "                mode = 'constant', \n",
    "                constant_values=0\n",
    "            )\n",
    "            pltc = np.pad(\n",
    "                plc[i][- j: ].reshape(1,j,plc.shape[2]),\n",
    "                ((0, 0), (timesteps + 1 - j, 0), (0, 0)),\n",
    "                mode = 'constant', \n",
    "                constant_values=0\n",
    "            )\n",
    "            xee = np.append(xee,xt, axis = 0)\n",
    "            yee = np.append(yee,yt, axis = 0)\n",
    "            plee = np.append(plee,pltt, axis = 0)\n",
    "            plecc = np.append(plecc,pltc, axis = 0)\n",
    "\n",
    "    return xtt,ytt,plttt, pltcc,xee,yee,plee,plecc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed3678f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNXFMCG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XBANK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NIFTYQUALITY30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           symbol\n",
       "0         CNXFMCG\n",
       "1           XBANK\n",
       "2  NIFTYQUALITY30"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_main = pd.read_csv('../../data/market_indices.csv', index_col = [0])\n",
    "df_main.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ba9cdc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNXFMCG\n",
      "Epoch 1/400\n",
      "32/32 [==============================] - 3s 15ms/step - loss: 1.6647 - accuracy: 0.3085\n",
      "Epoch 2/400\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 1.4678 - accuracy: 0.4206\n",
      "Epoch 3/400\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 1.3335 - accuracy: 0.5248\n",
      "Epoch 4/400\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.1896 - accuracy: 0.5784\n",
      "Epoch 5/400\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 1.0658 - accuracy: 0.6518\n",
      "Epoch 6/400\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.9302 - accuracy: 0.7262\n",
      "Epoch 7/400\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.8123 - accuracy: 0.7837\n",
      "Epoch 8/400\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.6907 - accuracy: 0.8333\n",
      "Epoch 9/400\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.5815 - accuracy: 0.8780\n",
      "Epoch 10/400\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.4876 - accuracy: 0.9087\n",
      "Epoch 11/400\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.4142 - accuracy: 0.9117\n",
      "Epoch 12/400\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.3641 - accuracy: 0.9286\n",
      "Epoch 13/400\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.3085 - accuracy: 0.9415\n",
      "Epoch 14/400\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.2887 - accuracy: 0.9415\n",
      "Epoch 15/400\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.2507 - accuracy: 0.9454\n",
      "Epoch 16/400\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.2207 - accuracy: 0.9613\n",
      "Epoch 17/400\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.1974 - accuracy: 0.9623\n",
      "Epoch 18/400\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.1752 - accuracy: 0.9732\n",
      "Epoch 19/400\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.1594 - accuracy: 0.9702\n",
      "Epoch 20/400\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.1584 - accuracy: 0.9772\n",
      "Epoch 21/400\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.1393 - accuracy: 0.9831\n",
      "Epoch 22/400\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.1308 - accuracy: 0.9802\n",
      "Epoch 23/400\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.1118 - accuracy: 0.9871\n",
      "Epoch 24/400\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.1085 - accuracy: 0.9831\n",
      "Epoch 25/400\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.0989 - accuracy: 0.9871\n",
      "Epoch 26/400\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.1010 - accuracy: 0.9762\n",
      "Epoch 27/400\n",
      "32/32 [==============================] - 0s 16ms/step - loss: 0.0863 - accuracy: 0.9881\n",
      "Epoch 28/400\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0851 - accuracy: 0.9891\n",
      "Epoch 29/400\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.0731 - accuracy: 0.9931\n",
      "Epoch 30/400\n",
      "32/32 [==============================] - 1s 18ms/step - loss: 0.0701 - accuracy: 0.9931\n",
      "Epoch 31/400\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.0689 - accuracy: 0.9931\n",
      "Epoch 32/400\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0623 - accuracy: 0.9940\n",
      "Epoch 33/400\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9960\n",
      "Desired accuracy reached. Stopping training.\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.0561 - accuracy: 0.9960\n",
      "14/14 [==============================] - 1s 7ms/step\n",
      "CPU times: user 59.4 s, sys: 20.6 s, total: 1min 19s\n",
      "Wall time: 32.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import gc\n",
    "\n",
    "class StopAtAccuracy(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, target=0.995):\n",
    "        super().__init__()\n",
    "        self.target = target\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        acc = logs.get(\"accuracy\")  # Use \"val_accuracy\" if you're using validation accuracy\n",
    "        if acc is not None and acc >= self.target:\n",
    "            print(f\"\\nDesired accuracy reached. Stopping training.\")\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "def run_simulation(i):\n",
    "    try:\n",
    "        timesteps = 3 #4\n",
    "        sli = 108\n",
    "        sym = '../data/Database_sh_backup/' + i + '.csv'\n",
    "\n",
    "        dff,times,df = data_maker_pom_test (sym)\n",
    "\n",
    "\n",
    "        fd, col , tdf = prepare_data_com_pom(dff.copy(),sym,times,timesteps)\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(fd[['pl']][:len(fd) - sli])\n",
    "        fd['pl'] = scaler.transform(fd[['pl']])\n",
    "        fd,tup = plc_pom(fd)\n",
    "        x,y,pl,plc = splitter_com(fd,timesteps)\n",
    "        xt, yt, pltt, pltc,xe, ye, ple, plec = padder_com(x,y,pl,plc,sli,timesteps)\n",
    "        otr = np.array([ [1 if i[0] == 1 else 0 ,0 if i[0] == 1 else 1]  for i in yt[:,-1,:]])\n",
    "        ote = np.array([ [1 if i[0] == 1 else 0 ,0 if i[0] == 1 else 1]  for i in ye[:,-1,:]])\n",
    "        otrc = np.array(\n",
    "        [\n",
    "            [\n",
    "                1 if i[0] == -3 else 0 ,\n",
    "                1 if i[0] == -2 else 0 ,\n",
    "                1 if i[0] == -1 else 0 ,\n",
    "                1 if i[0] == 1 else 0 ,\n",
    "                1 if i[0] == 2 else 0 ,\n",
    "                1 if i[0] == 3 else 0\n",
    "            ]  for i in pltc[:,-1,:]\n",
    "        ]\n",
    "        )\n",
    "        otec = np.array(\n",
    "        [\n",
    "            [\n",
    "                1 if i[0] == -3 else 0 ,\n",
    "                1 if i[0] == -2 else 0 ,\n",
    "                1 if i[0] == -1 else 0 ,\n",
    "                1 if i[0] == 1 else 0 ,\n",
    "                1 if i[0] == 2 else 0 ,\n",
    "                1 if i[0] == 3 else 0\n",
    "            ]  for i in plec[:,-1,:]\n",
    "        ]\n",
    "        )\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        \n",
    "        model.add(LSTM(128, input_shape=(3, 162), return_sequences=False))\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "        model.add(Dense(6, activation='softmax'))  # Softmax for multiclass\n",
    "\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        timess = 400\n",
    "        model.fit(\n",
    "            xt[:, 1:, :], otrc[:],\n",
    "            epochs=timess,\n",
    "            callbacks=[StopAtAccuracy(target=0.995)]\n",
    "        )\n",
    "\n",
    "        yp = model.predict(xe[:, 1:, :])\n",
    "        model.save(\"../cmg_results/LSTM/models/\"+i+'.h5')\n",
    "        del model\n",
    "        gc.collect()\n",
    "        count = 0\n",
    "        li = []\n",
    "        for ii in yp:\n",
    "            if (count+1)%4 == 0:\n",
    "                if (ii[0] + ii[1] + ii[2])>  (ii[3]+ii[4] + ii[5]):\n",
    "                    li.append(0)\n",
    "                else:\n",
    "                    li.append(1)\n",
    "            count += 1\n",
    "\n",
    "        y_pred = pd.DataFrame(li, columns = ['pred'])\n",
    "        y_pred['timestamp'] = list(list ( tdf[-int(len(yp)/4):]['timestamp'].apply(lambda x:x.split(' ')[0])))\n",
    "        y_pred = y_pred [['timestamp', 'pred']]\n",
    "\n",
    "# ================================================\n",
    "# ⚠️ OHLC Data Usage (Commented Out)\n",
    "# ================================================\n",
    "# This section of the code utilizes OHLC (Open, High, Low, Close) financial market data.\n",
    "# Due to licensing restrictions, the actual OHLC dataset used in this project cannot be\n",
    "# uploaded or distributed publicly via this repository.\n",
    "#\n",
    "# Many OHLC data sources (e.g., Yahoo Finance, Bloomberg, NSE, etc.) allow personal or\n",
    "# research use, but prohibit redistribution or public sharing of the data files.\n",
    "#\n",
    "# To reproduce results:\n",
    "# - You may use your own OHLC data.\n",
    "# - Or modify the script to fetch data from APIs (e.g., yfinance).\n",
    "#\n",
    "# =================================================\n",
    "#         ori = '../data/Database_backup/'\n",
    "#         ori_df = pd.read_csv(ori, index_col = [0])    \n",
    "#         dt_end = datetime.strptime(y_pred.iloc[-1]['timestamp'],'%Y-%m-%d')\n",
    "#         acc = pd.DataFrame(columns = ['date','accuracy', 'potential'])\n",
    "#         for ind , row in y_pred.iterrows():\n",
    "#             dt = datetime.strptime(row.timestamp,'%Y-%m-%d')\n",
    "#             dt_orig = dt\n",
    "#             close_previous = ori_df [ori_df.datetime.str.contains(dt_orig.strftime('%Y-%m-%d'))].iloc[-1].close\n",
    "#             checker = 0\n",
    "#             while True:\n",
    "#                 dt += timedelta(days = 1)\n",
    "#                 if dt > dt_end:\n",
    "#                     checker = 1\n",
    "#                     break\n",
    "#                 sd = ori_df[ori_df.datetime.str.contains(dt.strftime('%Y-%m-%d'))].copy()\n",
    "#                 if len(sd) > 0:\n",
    "#                     break\n",
    "#             if checker == 1:\n",
    "#                 continue\n",
    "#             if len(sd) > 0:\n",
    "#                 sdd = sd[:int(len(sd) / 4)] #first quarter\n",
    "#                 check = 0\n",
    "#                 tmp = -1\n",
    "#                 for indd, roww in sdd.iterrows():\n",
    "#                     if row.pred == 1:\n",
    "#                         if roww.close > close_previous:\n",
    "#                             if tmp < (roww.close - close_previous):\n",
    "#                                 tmp = roww.close - close_previous\n",
    "#                             check = 1\n",
    "#                     else:\n",
    "#                         if roww.close < close_previous:\n",
    "#                             if tmp < (close_previous - roww.close):\n",
    "#                                 tmp = close_previous - roww.close\n",
    "#                             check = 1\n",
    "#                 if check == 1:\n",
    "#                     acc = pd.concat([acc, pd.DataFrame(\n",
    "#                         [[dt_orig.strftime('%Y-%m-%d'), check, tmp]], columns =  ['date','accuracy', 'potential'])]\n",
    "#                                    )\n",
    "#                 else : \n",
    "#                     acc = pd.concat([acc, pd.DataFrame(\n",
    "#                         [[dt_orig.strftime('%Y-%m-%d'), check, tmp]], columns =  ['date','accuracy', 'potential'])]\n",
    "#                                    )\n",
    "\n",
    "#         acc.to_csv(\"results/LSTM/accuracy/\"+i+\".csv\")           \n",
    "#         print(i,acc['accuracy'].mean())\n",
    "        gc.collect()\n",
    "#         clear_output(wait=False)\n",
    "    except Exception as e:\n",
    "        print(\"❌ An error occurred:\")\n",
    "        traceback.print_exc()\n",
    "        gc.collect()\n",
    "for i in df_main.symbol:    \n",
    "    print(i)\n",
    "    run_simulation(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "836e8f63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83842f19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forex",
   "language": "python",
   "name": "forex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
