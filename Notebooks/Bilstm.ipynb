{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9259f585",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 11:13:42.287728: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "import mysql.connector\n",
    "import glob\n",
    "import traceback\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from IPython.display import clear_output\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29798735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_maker_pom_test (i):\n",
    "    df = pd.read_csv(i, index_col = [0])\n",
    "    df = df.iloc[df[df.timestamp.str.contains(df.timestamp.apply(lambda x: x.split(' ')[0]).unique()[-360])].iloc[0].name:]\n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "    times = pd.DataFrame(df['timestamp'])\n",
    "    pl = pd.DataFrame(df['pl'])\n",
    "    dff = pd.DataFrame()\n",
    "    st = datetime.strptime(df.timestamp.iloc[ 0 ], '%Y-%m-%d %H:%M:%S') #+ timedelta(days = 1)\n",
    "    et = datetime.strptime(df.timestamp.iloc[-1 ], '%Y-%m-%d %H:%M:%S')\n",
    "    while True:\n",
    "        if st > et + timedelta(days = 1):\n",
    "            break\n",
    "        srt = datetime.strftime(st , '%Y-%m-%d %H:%M:%S')\n",
    "        tmp = df[df['timestamp'].str.contains(srt.split(' ')[0])].copy()\n",
    "        tmp.drop(columns = ['timestamp'], inplace = True)\n",
    "        lis = list(tmp.columns)\n",
    "        if len(tmp) == 0:\n",
    "            st += timedelta(days = 1)\n",
    "            continue\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(tmp)\n",
    "        tmp = scaler.transform(tmp)\n",
    "        \n",
    "        tmp = pd.DataFrame(tmp, columns = lis)\n",
    "        dff = pd.concat([\n",
    "            dff,\n",
    "            tmp\n",
    "        ])\n",
    "        del scaler\n",
    "        st += timedelta(days = 1)\n",
    "    dff.reset_index(drop = True, inplace = True)\n",
    "    dff['pl'] = pl['pl']\n",
    "    return dff,times,df\n",
    "\n",
    "def prepare_data_com_pom(df,i,times,timesteps):\n",
    "    pl = df[['pl']]\n",
    "    df['class'] = [1 if j[0] >0 else 0 for j in pl.values]\n",
    "    y = df[['class']]\n",
    "    df['pl'] = pl\n",
    "    df['class'] = y\n",
    "    col = list(df.columns)\n",
    "    tdf = pd.DataFrame(columns = ['timestamp'])\n",
    "    \n",
    "    dt = times.iloc[0].values[0]\n",
    "    dt = dt.split(' ')[0]\n",
    "    et = times.iloc[-1].values[0]\n",
    "    et = et.split(' ')[0]\n",
    "    dtt = datetime.strptime(dt, '%Y-%m-%d')\n",
    "    ett = datetime.strptime(et, '%Y-%m-%d')\n",
    "    fd = pd.DataFrame(columns = col)\n",
    "    fdd = df.copy()\n",
    "    while dtt < ett + timedelta(days = 1):\n",
    "        \n",
    "        try:\n",
    "            ind = times[times['timestamp'].str.contains(dtt.strftime('%Y-%m-%d'))].iloc[-1].name\n",
    "            tdf = pd.concat([\n",
    "                tdf,\n",
    "                pd.DataFrame(\n",
    "                    times[\n",
    "                        times['timestamp'].str.contains(\n",
    "                            dtt.strftime('%Y-%m-%d')\n",
    "                        )].iloc[-1]\n",
    "                ).T\n",
    "            ])\n",
    "        except:\n",
    "            dtt+= timedelta(days = 1)\n",
    "            continue \n",
    "        ad = pd.DataFrame(fdd.loc[ind-timesteps:ind],columns = col)\n",
    "        ad = ad[col]\n",
    "        fd = pd.concat([\n",
    "            fd,\n",
    "            ad\n",
    "        ])\n",
    "        dtt += timedelta(days = 1)\n",
    "    fd.reset_index(drop = True, inplace = True)\n",
    "    col = fd.columns\n",
    "    return fd, col,tdf\n",
    "\n",
    "def plc_pom(fd):\n",
    "    data = fd['pl']\n",
    "    range_50 = np.percentile(data, [16, 84]) \n",
    "    range_75 = np.percentile(data, [3, 97])  \n",
    "    range_100 = np.percentile(data, [0, 100])\n",
    "    fd['plc'] = fd['pl'].apply(\n",
    "        lambda x : 1 if (x <= range_50[1] and x > 0 ) else( \n",
    "            -1\n",
    "            if (x > range_50[0] and x < 0) else(\n",
    "                2\n",
    "                if (x > range_50[1] and x < range_75[1]) else(\n",
    "                    -2\n",
    "                    if (x < range_50[0] and x > range_75[0]) else (\n",
    "                        3 if (x > range_75[1]) else(\n",
    "                            -3 if (x < range_75[0]) else 0\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return fd, (range_50,range_75,range_100)\n",
    "\n",
    "def plc_pom_4(fd):\n",
    "    data = fd['pl']\n",
    "    range_45 = np.percentile(data, [27.5, 72.5])\n",
    "    range_50 = np.percentile(data, [16, 84]) \n",
    "    range_75 = np.percentile(data, [3, 97])  \n",
    "    range_100 = np.percentile(data, [0, 100])\n",
    "    fd['plc'] = fd['pl'].apply(\n",
    "        lambda x : 1 if (x > 0 and x <= range_45[1]) else(\n",
    "            -1 if(x<0 and x > range_45[0] ) else(\n",
    "            2 if(x >= range_45[1] and x < range_50[1]) else(\n",
    "            -2 if (x <= range_45[0] and x > range_50[0]) else(\n",
    "            3 if (x >= range_50[1] and x < range_75[1]) else(\n",
    "            -3 if (x <= range_50[0] and x > range_75[0]) else(\n",
    "            4 if (x >= range_75[1]) else (\n",
    "            -4 if (x <= range_75[0]) else 0\n",
    "            )\n",
    "            )\n",
    "            )\n",
    "            )\n",
    "            )\n",
    "        )\n",
    "    ))\n",
    "    return fd, (range_50,range_75,range_100)\n",
    "\n",
    "def splitter_com(df,timesteps):\n",
    "    xx = np.empty((0,timesteps + 1,len(df.columns) - 3))\n",
    "    yy = np.empty((0,timesteps + 1 ,1))\n",
    "    pll = np.empty((0,timesteps + 1 , 1))\n",
    "    plcc = np.empty((0,timesteps + 1 , 1))\n",
    "    \n",
    "    yt = df[['class']]\n",
    "    pltt = df[['pl']]\n",
    "    pltc = df[['plc']]\n",
    "    \n",
    "    loop = len(df) / (timesteps+1)\n",
    "    for i in range(0,int(loop)):\n",
    "        x = df.loc[i*(timesteps+1): ((i+1) *(timesteps + 1 )) - 1].copy()\n",
    "        y = yt.loc[i*(timesteps+1): ((i+1) *(timesteps + 1 )) - 1]\n",
    "        pl = pltt.loc[i*(timesteps+1): ((i+1) *(timesteps + 1 )) - 1]\n",
    "        plc = pltc.loc[i*(timesteps+1): ((i+1) *(timesteps + 1 )) - 1]\n",
    "        \n",
    "        x.drop(columns = ['class','pl','plc'], inplace = True)\n",
    "        x = np.array(x).reshape(1,timesteps+1,len(x.columns))\n",
    "        y = np.array(y).reshape(1,timesteps+1,1)\n",
    "        pl = np.array(pl).reshape(1,timesteps+1,1)\n",
    "        plc = np.array(plc).reshape(1,timesteps+1,1)\n",
    "        \n",
    "        xx = np.append(xx,x,axis = 0)\n",
    "        yy = np.append(yy,y, axis = 0)\n",
    "        pll = np.append(pll,pl, axis = 0)\n",
    "        plcc = np.append(plcc,plc, axis = 0)\n",
    "    return xx,yy,pll,plcc\n",
    "\n",
    "def padder_com(x,y,pl,plc,sli,timesteps):\n",
    "    xtt = np.empty((0,timesteps+1,x.shape[2]))\n",
    "    ytt = np.empty((0,timesteps+1,y.shape[2]))\n",
    "    plttt = np.empty((0,timesteps+1,pl.shape[2]))\n",
    "    pltcc = np.empty((0,timesteps+1,plc.shape[2]))\n",
    "    xee = np.empty((0,timesteps+1,x.shape[2]))\n",
    "    yee = np.empty((0,timesteps+1,y.shape[2]))\n",
    "    plee = np.empty((0,timesteps+1,pl.shape[2]))\n",
    "    plecc = np.empty((0,timesteps+1,plc.shape[2]))\n",
    "    for i in range(0,len(x) - sli):\n",
    "        for j in range(1,timesteps+2):\n",
    "            xt = np.pad(\n",
    "                x[i][- j: ].reshape(1,j,x.shape[2]),\n",
    "                ((0, 0), (timesteps + 1 -j, 0), (0, 0)),\n",
    "                mode = 'constant',\n",
    "                constant_values=-1\n",
    "            )\n",
    "            yt = np.pad(\n",
    "                y[i][- j: ].reshape(1,j,y.shape[2]),\n",
    "                ((0, 0), (timesteps + 1-j, 0), (0, 0)),\n",
    "                mode = 'constant', \n",
    "                constant_values=-1\n",
    "            )\n",
    "            pltt = np.pad(\n",
    "                pl[i][- j: ].reshape(1,j,pl.shape[2]),\n",
    "                ((0, 0), (timesteps + 1 - j , 0), (0, 0)),\n",
    "                mode = 'constant', \n",
    "                constant_values=0\n",
    "            )\n",
    "            pltc = np.pad(\n",
    "                plc[i][- j: ].reshape(1,j,plc.shape[2]),\n",
    "                ((0, 0), (timesteps + 1 - j , 0), (0, 0)),\n",
    "                mode = 'constant', \n",
    "                constant_values=0\n",
    "            )\n",
    "            xtt = np.append(xtt,xt, axis = 0)\n",
    "            ytt = np.append(ytt,yt, axis = 0)\n",
    "            plttt = np.append(plttt,pltt, axis = 0)\n",
    "            pltcc = np.append(pltcc,pltc, axis = 0)\n",
    "    for i in range(len(x) - sli, len(x)):\n",
    "        for j in range(1,timesteps+2):\n",
    "            xt = np.pad(\n",
    "                x[i][- j: ].reshape(1,j,x.shape[2]),\n",
    "                ((0, 0), (timesteps + 1 - j, 0), (0, 0)),\n",
    "                mode = 'constant', \n",
    "                constant_values=-1\n",
    "            )\n",
    "            yt = np.pad(\n",
    "                y[i][- j: ].reshape(1,j,y.shape[2]),\n",
    "                ((0, 0), (timesteps + 1 - j, 0), (0, 0)),\n",
    "                mode = 'constant', \n",
    "                constant_values=-1\n",
    "            )\n",
    "            pltt = np.pad(\n",
    "                pl[i][- j: ].reshape(1,j,pl.shape[2]),\n",
    "                ((0, 0), (timesteps + 1 - j, 0), (0, 0)),\n",
    "                mode = 'constant', \n",
    "                constant_values=0\n",
    "            )\n",
    "            pltc = np.pad(\n",
    "                plc[i][- j: ].reshape(1,j,plc.shape[2]),\n",
    "                ((0, 0), (timesteps + 1 - j, 0), (0, 0)),\n",
    "                mode = 'constant', \n",
    "                constant_values=0\n",
    "            )\n",
    "            xee = np.append(xee,xt, axis = 0)\n",
    "            yee = np.append(yee,yt, axis = 0)\n",
    "            plee = np.append(plee,pltt, axis = 0)\n",
    "            plecc = np.append(plecc,pltc, axis = 0)\n",
    "\n",
    "    return xtt,ytt,plttt, pltcc,xee,yee,plee,plecc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a099186",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_bilstm_classifier(input_dim, hidden_dim, num_classes, sequence_length):\n",
    "    inputs = layers.Input(shape=(sequence_length, input_dim))\n",
    "    x = layers.Bidirectional(layers.LSTM(hidden_dim))(inputs)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    return models.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d239e9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNXFMCG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XBANK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NIFTYQUALITY30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           symbol\n",
       "0         CNXFMCG\n",
       "1           XBANK\n",
       "2  NIFTYQUALITY30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_main = pd.read_csv('../data/market_indices.csv', index_col = [0])\n",
    "df_main.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cb63380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 51min 21s, sys: 18min 7s, total: 2h 9min 28s\n",
      "Wall time: 1h 16min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "class StopAtAccuracy(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, target=0.995):\n",
    "        super().__init__()\n",
    "        self.target = target\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        acc = logs.get(\"accuracy\")  # Use \"val_accuracy\" if you're using validation accuracy\n",
    "        if acc is not None and acc >= self.target:\n",
    "            print(f\"\\nDesired accuracy reached. Stopping training.\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "def run_simulation(i):\n",
    "    try:\n",
    "        timesteps = 3 #4\n",
    "        sli = 108\n",
    "        sym = '../data/Database_sh_backup/' + i + '.csv'\n",
    "\n",
    "        dff,times,df = data_maker_pom_test (sym)\n",
    "\n",
    "\n",
    "        fd, col , tdf = prepare_data_com_pom(dff.copy(),sym,times,timesteps)\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(fd[['pl']][:len(fd) - sli])\n",
    "        fd['pl'] = scaler.transform(fd[['pl']])\n",
    "        fd,tup = plc_pom(fd)\n",
    "        x,y,pl,plc = splitter_com(fd,timesteps)\n",
    "        xt, yt, pltt, pltc,xe, ye, ple, plec = padder_com(x,y,pl,plc,sli,timesteps)\n",
    "        otr = np.array([ [1 if i[0] == 1 else 0 ,0 if i[0] == 1 else 1]  for i in yt[:,-1,:]])\n",
    "        ote = np.array([ [1 if i[0] == 1 else 0 ,0 if i[0] == 1 else 1]  for i in ye[:,-1,:]])\n",
    "        otrc = np.array(\n",
    "        [\n",
    "            [\n",
    "                1 if i[0] == -3 else 0 ,\n",
    "                1 if i[0] == -2 else 0 ,\n",
    "                1 if i[0] == -1 else 0 ,\n",
    "                1 if i[0] == 1 else 0 ,\n",
    "                1 if i[0] == 2 else 0 ,\n",
    "                1 if i[0] == 3 else 0\n",
    "            ]  for i in pltc[:,-1,:]\n",
    "        ]\n",
    "        )\n",
    "        otec = np.array(\n",
    "        [\n",
    "            [\n",
    "                1 if i[0] == -3 else 0 ,\n",
    "                1 if i[0] == -2 else 0 ,\n",
    "                1 if i[0] == -1 else 0 ,\n",
    "                1 if i[0] == 1 else 0 ,\n",
    "                1 if i[0] == 2 else 0 ,\n",
    "                1 if i[0] == 3 else 0\n",
    "            ]  for i in plec[:,-1,:]\n",
    "        ]\n",
    "        )\n",
    "        model = build_bilstm_classifier(162, 128, 6, 3)\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "        timess = 400\n",
    "        model.fit(\n",
    "            xt[:, 1:, :], otrc[:],\n",
    "            epochs=timess,\n",
    "            callbacks=[StopAtAccuracy(target=0.995)]\n",
    "        )\n",
    "\n",
    "        yp = model.predict(xe[:, 1:, :])\n",
    "        model.save(\"../cmg_results/Bilstm/models/\"+i+'.h5')\n",
    "        del model\n",
    "\n",
    "        count = 0\n",
    "        li = []\n",
    "        for ii in yp:\n",
    "            if (count+1)%4 == 0:\n",
    "                if (ii[0] + ii[1] + ii[2]) > (ii[3] + ii[4] + ii[5]):\n",
    "                    li.append(0)\n",
    "                else:\n",
    "                    li.append(1)\n",
    "            count += 1\n",
    "\n",
    "        y_pred = pd.DataFrame(li, columns = ['pred'])\n",
    "        y_pred['timestamp'] = list(list ( tdf[-int(len(yp)/4):]['timestamp'].apply(lambda x:x.split(' ')[0])))\n",
    "        y_pred = y_pred [['timestamp', 'pred']]\n",
    "\n",
    "# ================================================\n",
    "# ⚠️ OHLC Data Usage (Commented Out)\n",
    "# ================================================\n",
    "# This section of the code utilizes OHLC (Open, High, Low, Close) financial market data.\n",
    "# Due to licensing restrictions, the actual OHLC dataset used in this project cannot be\n",
    "# uploaded or distributed publicly via this repository.\n",
    "#\n",
    "# Many OHLC data sources (e.g., Yahoo Finance, Bloomberg, NSE, etc.) allow personal or\n",
    "# research use, but prohibit redistribution or public sharing of the data files.\n",
    "#\n",
    "# To reproduce results:\n",
    "# - You may use your own OHLC data.\n",
    "# - Or modify the script to fetch data from APIs (e.g., yfinance).\n",
    "#\n",
    "# =================================================\n",
    "\n",
    "#         ori = '../data/Database_backup/'\n",
    "#         ori_df = pd.read_csv(ori, index_col = [0])    \n",
    "#         dt_end = datetime.strptime(y_pred.iloc[-1]['timestamp'],'%Y-%m-%d')\n",
    "#         acc = pd.DataFrame(columns = ['date','accuracy', 'potential'])\n",
    "#         for ind , row in y_pred.iterrows():\n",
    "#             dt = datetime.strptime(row.timestamp,'%Y-%m-%d')\n",
    "#             dt_orig = dt\n",
    "#             close_previous = ori_df [ori_df.datetime.str.contains(dt_orig.strftime('%Y-%m-%d'))].iloc[-1].close\n",
    "#             checker = 0\n",
    "#             while True:\n",
    "#                 dt += timedelta(days = 1)\n",
    "#                 if dt > dt_end:\n",
    "#                     checker = 1\n",
    "#                     break\n",
    "#                 sd = ori_df[ori_df.datetime.str.contains(dt.strftime('%Y-%m-%d'))].copy()\n",
    "#                 if len(sd) > 0:\n",
    "#                     break\n",
    "#             if checker == 1:\n",
    "#                 continue\n",
    "#             if len(sd) > 0:\n",
    "#                 sdd = sd[:int(len(sd) / 4)] #first quarter\n",
    "#                 check = 0\n",
    "#                 tmp = -1\n",
    "#                 for indd, roww in sdd.iterrows():\n",
    "#                     if row.pred == 1:\n",
    "#                         if roww.close > close_previous:\n",
    "#                             if tmp < (roww.close - close_previous):\n",
    "#                                 tmp = roww.close - close_previous\n",
    "#                             check = 1\n",
    "#                     else:\n",
    "#                         if roww.close < close_previous:\n",
    "#                             if tmp < (close_previous - roww.close):\n",
    "#                                 tmp = close_previous - roww.close\n",
    "#                             check = 1\n",
    "#                 if check == 1:\n",
    "#                     acc = pd.concat([acc, pd.DataFrame(\n",
    "#                         [[dt_orig.strftime('%Y-%m-%d'), check, tmp]], columns =  ['date','accuracy', 'potential'])]\n",
    "#                                    )\n",
    "#                 else : \n",
    "#                     acc = pd.concat([acc, pd.DataFrame(\n",
    "#                         [[dt_orig.strftime('%Y-%m-%d'), check, tmp]], columns =  ['date','accuracy', 'potential'])]\n",
    "#                                    )\n",
    "\n",
    "#         acc.to_csv(\"results/Bilstm/accuracy/\"+i+\".csv\")           \n",
    "#         print(i,acc['accuracy'].mean())\n",
    "#         clear_output(wait=True)\n",
    "    except Exception as e:\n",
    "        print(\"❌ An error occurred:\")\n",
    "        traceback.print_exc()\n",
    "        \n",
    "for i in df_main.symbol:\n",
    "    print(i)\n",
    "    run_simulation(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbd48ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forex",
   "language": "python",
   "name": "forex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
