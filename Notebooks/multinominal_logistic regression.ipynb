{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecbbc144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14d98ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "import mysql.connector\n",
    "import glob\n",
    "import traceback\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ed6f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "779999ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNXFMCG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XBANK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NIFTYQUALITY30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           symbol\n",
       "0         CNXFMCG\n",
       "1           XBANK\n",
       "2  NIFTYQUALITY30"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_main = pd.read_csv('../data/market_indices.csv', index_col = [0])\n",
    "df_main.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37d8c8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_maker_pom_test (i):\n",
    "    df = pd.read_csv(i, index_col = [0])\n",
    "    df = df.iloc[df[df.timestamp.str.contains(df.timestamp.apply(lambda x: x.split(' ')[0]).unique()[-360])].iloc[0].name:]\n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "    times = pd.DataFrame(df['timestamp'])\n",
    "    pl = pd.DataFrame(df['pl'])\n",
    "    dff = pd.DataFrame()\n",
    "    st = datetime.strptime(df.timestamp.iloc[ 0 ], '%Y-%m-%d %H:%M:%S') #+ timedelta(days = 1)\n",
    "    et = datetime.strptime(df.timestamp.iloc[-1 ], '%Y-%m-%d %H:%M:%S')\n",
    "    while True:\n",
    "        if st > et + timedelta(days = 1):\n",
    "            break\n",
    "        srt = datetime.strftime(st , '%Y-%m-%d %H:%M:%S')\n",
    "        tmp = df[df['timestamp'].str.contains(srt.split(' ')[0])].copy()\n",
    "        tmp.drop(columns = ['timestamp'], inplace = True)\n",
    "        lis = list(tmp.columns)\n",
    "        if len(tmp) == 0:\n",
    "            st += timedelta(days = 1)\n",
    "            continue\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(tmp)\n",
    "        tmp = scaler.transform(tmp)\n",
    "        \n",
    "        tmp = pd.DataFrame(tmp, columns = lis)\n",
    "        dff = pd.concat([\n",
    "            dff,\n",
    "            tmp\n",
    "        ])\n",
    "        del scaler\n",
    "        st += timedelta(days = 1)\n",
    "    dff.reset_index(drop = True, inplace = True)\n",
    "    dff['pl'] = pl['pl']\n",
    "    return dff,times,df\n",
    "\n",
    "def prepare_data_com_pom(df,i,times,timesteps):\n",
    "    pl = df[['pl']]\n",
    "    df['class'] = [1 if j[0] >0 else 0 for j in pl.values]\n",
    "    y = df[['class']]\n",
    "    df['pl'] = pl\n",
    "    df['class'] = y\n",
    "    col = list(df.columns)\n",
    "    tdf = pd.DataFrame(columns = ['timestamp'])\n",
    "    \n",
    "    dt = times.iloc[0].values[0]\n",
    "    dt = dt.split(' ')[0]\n",
    "    et = times.iloc[-1].values[0]\n",
    "    et = et.split(' ')[0]\n",
    "    dtt = datetime.strptime(dt, '%Y-%m-%d')\n",
    "    ett = datetime.strptime(et, '%Y-%m-%d')\n",
    "    fd = pd.DataFrame(columns = col)\n",
    "    fdd = df.copy()\n",
    "    while dtt < ett + timedelta(days = 1):\n",
    "        \n",
    "        try:\n",
    "            ind = times[times['timestamp'].str.contains(dtt.strftime('%Y-%m-%d'))].iloc[-1].name\n",
    "            tdf = pd.concat([\n",
    "                tdf,\n",
    "                pd.DataFrame(\n",
    "                    times[\n",
    "                        times['timestamp'].str.contains(\n",
    "                            dtt.strftime('%Y-%m-%d')\n",
    "                        )].iloc[-1]\n",
    "                ).T\n",
    "            ])\n",
    "        except:\n",
    "            dtt+= timedelta(days = 1)\n",
    "            continue \n",
    "        ad = pd.DataFrame(fdd.loc[ind-timesteps:ind],columns = col)\n",
    "        ad = ad[col]\n",
    "        fd = pd.concat([\n",
    "            fd,\n",
    "            ad\n",
    "        ])\n",
    "        dtt += timedelta(days = 1)\n",
    "    fd.reset_index(drop = True, inplace = True)\n",
    "    col = fd.columns\n",
    "    return fd, col,tdf\n",
    "\n",
    "def plc_pom(fd):\n",
    "    data = fd['pl']\n",
    "    range_50 = np.percentile(data, [16, 84]) \n",
    "    range_75 = np.percentile(data, [3, 97])  \n",
    "    range_100 = np.percentile(data, [0, 100])\n",
    "    fd['plc'] = fd['pl'].apply(\n",
    "        lambda x : 1 if (x <= range_50[1] and x > 0 ) else( \n",
    "            -1\n",
    "            if (x > range_50[0] and x < 0) else(\n",
    "                2\n",
    "                if (x > range_50[1] and x < range_75[1]) else(\n",
    "                    -2\n",
    "                    if (x < range_50[0] and x > range_75[0]) else (\n",
    "                        3 if (x > range_75[1]) else(\n",
    "                            -3 if (x < range_75[0]) else 0\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return fd, (range_50,range_75,range_100)\n",
    "\n",
    "def plc_pom_4(fd):\n",
    "    data = fd['pl']\n",
    "    range_45 = np.percentile(data, [27.5, 72.5])\n",
    "    range_50 = np.percentile(data, [16, 84]) \n",
    "    range_75 = np.percentile(data, [3, 97])  \n",
    "    range_100 = np.percentile(data, [0, 100])\n",
    "    fd['plc'] = fd['pl'].apply(\n",
    "        lambda x : 1 if (x > 0 and x <= range_45[1]) else(\n",
    "            -1 if(x<0 and x > range_45[0] ) else(\n",
    "            2 if(x >= range_45[1] and x < range_50[1]) else(\n",
    "            -2 if (x <= range_45[0] and x > range_50[0]) else(\n",
    "            3 if (x >= range_50[1] and x < range_75[1]) else(\n",
    "            -3 if (x <= range_50[0] and x > range_75[0]) else(\n",
    "            4 if (x >= range_75[1]) else (\n",
    "            -4 if (x <= range_75[0]) else 0\n",
    "            )\n",
    "            )\n",
    "            )\n",
    "            )\n",
    "            )\n",
    "        )\n",
    "    ))\n",
    "    return fd, (range_50,range_75,range_100)\n",
    "\n",
    "def splitter_com(df,timesteps):\n",
    "    xx = np.empty((0,timesteps + 1,len(df.columns) - 3))\n",
    "    yy = np.empty((0,timesteps + 1 ,1))\n",
    "    pll = np.empty((0,timesteps + 1 , 1))\n",
    "    plcc = np.empty((0,timesteps + 1 , 1))\n",
    "    \n",
    "    yt = df[['class']]\n",
    "    pltt = df[['pl']]\n",
    "    pltc = df[['plc']]\n",
    "    \n",
    "    loop = len(df) / (timesteps+1)\n",
    "    for i in range(0,int(loop)):\n",
    "        x = df.loc[i*(timesteps+1): ((i+1) *(timesteps + 1 )) - 1].copy()\n",
    "        y = yt.loc[i*(timesteps+1): ((i+1) *(timesteps + 1 )) - 1]\n",
    "        pl = pltt.loc[i*(timesteps+1): ((i+1) *(timesteps + 1 )) - 1]\n",
    "        plc = pltc.loc[i*(timesteps+1): ((i+1) *(timesteps + 1 )) - 1]\n",
    "        \n",
    "        x.drop(columns = ['class','pl','plc'], inplace = True)\n",
    "        x = np.array(x).reshape(1,timesteps+1,len(x.columns))\n",
    "        y = np.array(y).reshape(1,timesteps+1,1)\n",
    "        pl = np.array(pl).reshape(1,timesteps+1,1)\n",
    "        plc = np.array(plc).reshape(1,timesteps+1,1)\n",
    "        \n",
    "        xx = np.append(xx,x,axis = 0)\n",
    "        yy = np.append(yy,y, axis = 0)\n",
    "        pll = np.append(pll,pl, axis = 0)\n",
    "        plcc = np.append(plcc,plc, axis = 0)\n",
    "    return xx,yy,pll,plcc\n",
    "\n",
    "def padder_com(x,y,pl,plc,sli,timesteps):\n",
    "    xtt = np.empty((0,timesteps+1,x.shape[2]))\n",
    "    ytt = np.empty((0,timesteps+1,y.shape[2]))\n",
    "    plttt = np.empty((0,timesteps+1,pl.shape[2]))\n",
    "    pltcc = np.empty((0,timesteps+1,plc.shape[2]))\n",
    "    xee = np.empty((0,timesteps+1,x.shape[2]))\n",
    "    yee = np.empty((0,timesteps+1,y.shape[2]))\n",
    "    plee = np.empty((0,timesteps+1,pl.shape[2]))\n",
    "    plecc = np.empty((0,timesteps+1,plc.shape[2]))\n",
    "    for i in range(0,len(x) - sli):\n",
    "        for j in range(1,timesteps+2):\n",
    "            xt = np.pad(\n",
    "                x[i][- j: ].reshape(1,j,x.shape[2]),\n",
    "                ((0, 0), (timesteps + 1 -j, 0), (0, 0)),\n",
    "                mode = 'constant',\n",
    "                constant_values=-1\n",
    "            )\n",
    "            yt = np.pad(\n",
    "                y[i][- j: ].reshape(1,j,y.shape[2]),\n",
    "                ((0, 0), (timesteps + 1-j, 0), (0, 0)),\n",
    "                mode = 'constant', \n",
    "                constant_values=-1\n",
    "            )\n",
    "            pltt = np.pad(\n",
    "                pl[i][- j: ].reshape(1,j,pl.shape[2]),\n",
    "                ((0, 0), (timesteps + 1 - j , 0), (0, 0)),\n",
    "                mode = 'constant', \n",
    "                constant_values=0\n",
    "            )\n",
    "            pltc = np.pad(\n",
    "                plc[i][- j: ].reshape(1,j,plc.shape[2]),\n",
    "                ((0, 0), (timesteps + 1 - j , 0), (0, 0)),\n",
    "                mode = 'constant', \n",
    "                constant_values=0\n",
    "            )\n",
    "            xtt = np.append(xtt,xt, axis = 0)\n",
    "            ytt = np.append(ytt,yt, axis = 0)\n",
    "            plttt = np.append(plttt,pltt, axis = 0)\n",
    "            pltcc = np.append(pltcc,pltc, axis = 0)\n",
    "    for i in range(len(x) - sli, len(x)):\n",
    "        for j in range(1,timesteps+2):\n",
    "            xt = np.pad(\n",
    "                x[i][- j: ].reshape(1,j,x.shape[2]),\n",
    "                ((0, 0), (timesteps + 1 - j, 0), (0, 0)),\n",
    "                mode = 'constant', \n",
    "                constant_values=-1\n",
    "            )\n",
    "            yt = np.pad(\n",
    "                y[i][- j: ].reshape(1,j,y.shape[2]),\n",
    "                ((0, 0), (timesteps + 1 - j, 0), (0, 0)),\n",
    "                mode = 'constant', \n",
    "                constant_values=-1\n",
    "            )\n",
    "            pltt = np.pad(\n",
    "                pl[i][- j: ].reshape(1,j,pl.shape[2]),\n",
    "                ((0, 0), (timesteps + 1 - j, 0), (0, 0)),\n",
    "                mode = 'constant', \n",
    "                constant_values=0\n",
    "            )\n",
    "            pltc = np.pad(\n",
    "                plc[i][- j: ].reshape(1,j,plc.shape[2]),\n",
    "                ((0, 0), (timesteps + 1 - j, 0), (0, 0)),\n",
    "                mode = 'constant', \n",
    "                constant_values=0\n",
    "            )\n",
    "            xee = np.append(xee,xt, axis = 0)\n",
    "            yee = np.append(yee,yt, axis = 0)\n",
    "            plee = np.append(plee,pltt, axis = 0)\n",
    "            plecc = np.append(plecc,pltc, axis = 0)\n",
    "\n",
    "    return xtt,ytt,plttt, pltcc,xee,yee,plee,plecc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434e195f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be55ef0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minivest/miniconda3/envs/forex/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/minivest/miniconda3/envs/forex/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38 s, sys: 26 s, total: 1min 3s\n",
      "Wall time: 18.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def splits(yy):\n",
    "    li = []\n",
    "    tmp = pd.DataFrame()\n",
    "    count = 1\n",
    "    for i in range(int(len(yy)/4)):\n",
    "        tmp = pd.concat([tmp,pd.DataFrame(yy.iloc[4*count - 1])],axis = 1)\n",
    "        count+=1\n",
    "    return tmp.T\n",
    "\n",
    "def run_simulation(i):\n",
    "    try:\n",
    "        timesteps = 3 \n",
    "        sym = '../data/Database_sh_backup/' + i + '.csv'\n",
    "\n",
    "        dff,times,df = data_maker_pom_test (sym)\n",
    "\n",
    "        fd, col , tdf = prepare_data_com_pom(dff.copy(),sym,times,timesteps)\n",
    "        \n",
    "\n",
    "        ti_li = pd.to_datetime(\n",
    "            tdf['timestamp']\n",
    "        ).dt.date.repeat(4).reset_index(drop=True).astype(str)\n",
    "        fd['timestamp'] = ti_li\n",
    "\n",
    "        fd,tup = plc_pom(fd)\n",
    "        data = fd.copy()\n",
    "        time_stamp = data['timestamp']\n",
    "        data.drop(inplace = True, columns = ['pl', 'timestamp','class']) # extras\n",
    "        X = data.drop(columns = 'plc')\n",
    "        y = data['plc']\n",
    "        y = y - y.min()\n",
    "        \n",
    "        split_index = 108*4\n",
    "        X_train = X.iloc[:-split_index]\n",
    "        X_test = X.iloc[-split_index:]\n",
    "\n",
    "        y_train = y.iloc[:-split_index]\n",
    "        y_test = y.iloc[-split_index:]\n",
    "        y_test = pd.DataFrame(y_test).astype(int)\n",
    "        test_timestamp = time_stamp.iloc[-split_index:] \n",
    "        test_timestamp = pd.DataFrame(test_timestamp)\n",
    "         \n",
    "        y_train = LabelEncoder().fit_transform(y_train)\n",
    "        y_test = LabelEncoder().fit_transform(y_test)\n",
    "        y_train = pd.DataFrame(y_train, columns = ['plc'])\n",
    "        y_test = pd.DataFrame(y_test, columns = ['plc'])\n",
    "        \n",
    "        model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_test = splits(y_test)\n",
    "        X_test = splits(X_test)\n",
    "        test_timestamp = splits(test_timestamp)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred = pd.DataFrame(y_pred, columns = ['pred'])\n",
    "        y_pred['timestamp'] = list(test_timestamp['timestamp'])\n",
    "        y_pred = y_pred[['timestamp', 'pred']]\n",
    "        \n",
    "        y_pred['pred'] = y_pred['pred'].apply(lambda x: 1 if x > 2 else 0)\n",
    "        \n",
    "# ================================================\n",
    "# ⚠️ OHLC Data Usage (Commented Out)\n",
    "# ================================================\n",
    "# This section of the code utilizes OHLC (Open, High, Low, Close) financial market data.\n",
    "# Due to licensing restrictions, the actual OHLC dataset used in this project cannot be\n",
    "# uploaded or distributed publicly via this repository.\n",
    "#\n",
    "# Many OHLC data sources (e.g., Yahoo Finance, Bloomberg, NSE, etc.) allow personal or\n",
    "# research use, but prohibit redistribution or public sharing of the data files.\n",
    "#\n",
    "# To reproduce results:\n",
    "# - You may use your own OHLC data.\n",
    "# - Or modify the script to fetch data from APIs (e.g., yfinance).\n",
    "#\n",
    "# =================================================\n",
    "\n",
    "#         ori = '../data/Database_backup/' +i+'.csv'\n",
    "#         ori_df = pd.read_csv(ori, index_col = [0])    \n",
    "#         dt_end = datetime.strptime(y_pred.iloc[-1]['timestamp'],'%Y-%m-%d')\n",
    "#         acc = pd.DataFrame(columns = ['date','accuracy', 'potential'])\n",
    "#         for ind , row in y_pred.iterrows():\n",
    "#             dt = datetime.strptime(row.timestamp,'%Y-%m-%d')\n",
    "#             dt_orig = dt\n",
    "#             close_previous = ori_df [ori_df.datetime.str.contains(dt_orig.strftime('%Y-%m-%d'))].iloc[-1].close\n",
    "#             checker = 0\n",
    "#             while True:\n",
    "#                 dt += timedelta(days = 1)\n",
    "#                 if dt > dt_end:\n",
    "#                     checker = 1\n",
    "#                     break\n",
    "#                 sd = ori_df[ori_df.datetime.str.contains(dt.strftime('%Y-%m-%d'))].copy()\n",
    "#                 if len(sd) > 0:\n",
    "#                     break\n",
    "#             if checker == 1:\n",
    "#                 continue\n",
    "#             if len(sd) > 0:\n",
    "#                 sdd = sd[:int(len(sd) / 4)] #first quarter\n",
    "#                 check = 0\n",
    "#                 tmp = -1\n",
    "#                 for indd, roww in sdd.iterrows():\n",
    "#                     if row.pred > 2:\n",
    "#                         if roww.close > close_previous:\n",
    "#                             if tmp < (roww.close - close_previous):\n",
    "#                                 tmp = roww.close - close_previous\n",
    "#                             check = 1\n",
    "#                     else:\n",
    "#                         if roww.close < close_previous:\n",
    "#                             if tmp < (close_previous - roww.close):\n",
    "#                                 tmp = close_previous - roww.close\n",
    "#                             check = 1\n",
    "#                 if check == 1:\n",
    "#                     acc = pd.concat([acc, pd.DataFrame(\n",
    "#                         [[dt_orig.strftime('%Y-%m-%d'), check, tmp]], columns =  ['date','accuracy', 'potential'])]\n",
    "#                                    )\n",
    "#                 else : \n",
    "#                     acc = pd.concat([acc, pd.DataFrame(\n",
    "#                         [[dt_orig.strftime('%Y-%m-%d'), check, tmp]], columns =  ['date','accuracy', 'potential'])]\n",
    "#                                    )\n",
    "#         acc.to_csv(\"results/multi_logistic_regression/accuracy/\"+i+\".csv\")           \n",
    "#         print(i,acc['accuracy'].mean())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"❌ An error occurred:\")\n",
    "        traceback.print_exc()\n",
    "for i in df_main.symbol:\n",
    "    run_simulation(i)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81626930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fced89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forex",
   "language": "python",
   "name": "forex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
